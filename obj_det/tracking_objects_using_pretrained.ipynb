{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WXO03HLOWW0"
      },
      "outputs": [],
      "source": [
        "import mrcnn\n",
        "import mrcnn.config\n",
        "import mrcnn.model\n",
        "import mrcnn.visualize\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Known object classes in the video (including \"person\")\n",
        "KNOWN_CLASSES = ['person', 'phone', 'bag','scissor','frdige']"
      ],
      "metadata": {
        "id": "NKlRoIkROin2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold confidence levels for different classes\n",
        "CONFIDENCE_THRESHOLDS = {\n",
        "    'person': 0.8,  # High confidence threshold for person\n",
        "    'phone': 0.7,\n",
        "    'bag': 0.6,\n",
        "    'scissor':0.5,\n",
        "    'frdige':0.5\n",
        "}\n",
        "\n",
        "class SimpleConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_inference\"\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = len(KNOWN_CLASSES) + 1  # +1 for the background"
      ],
      "metadata": {
        "id": "He467tc4OjH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Mask R-CNN model for inference\n",
        "model = mrcnn.model.MaskRCNN(mode=\"inference\",\n",
        "                             config=SimpleConfig(),\n",
        "                             model_dir=os.getcwd())\n"
      ],
      "metadata": {
        "id": "Efv9KUp1OlSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained COCO weights\n",
        "model.load_weights(filepath=\"mask_rcnn_coco.h5\", by_name=True)"
      ],
      "metadata": {
        "id": "jAaZEgCWOnbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize video reader and writer\n",
        "video_path = \"input_video.mp4\"\n",
        "video_capture = cv2.VideoCapture(video_path)\n",
        "output_path = \"sample.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "fps = int(video_capture.get(cv2.CAP_PROP_FPS))\n",
        "width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
      ],
      "metadata": {
        "id": "uudlyw1fO5w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store previous boxes for tracking\n",
        "tracks = {cls: deque(maxlen=5) for cls in KNOWN_CLASSES}"
      ],
      "metadata": {
        "id": "kRml7XTZO7q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate IoU (Intersection over Union)\n",
        "def compute_iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x1_, y1_, x2_, y2_ = box2\n",
        "\n",
        "    xi1, yi1 = max(x1, x1_), max(y1, y1_)\n",
        "    xi2, yi2 = min(x2, x2_), min(y2, y2_)\n",
        "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
        "    box1_area = (x2 - x1) * (y2 - y1)\n",
        "    box2_area = (x2_ - x1_) * (y2_ - y1_)\n",
        "\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    iou = inter_area / union_area\n",
        "    return iou"
      ],
      "metadata": {
        "id": "xRmNi5z6O8vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to filter and track objects\n",
        "def process_detections(image, r):\n",
        "    boxes, class_ids, scores = r['rois'], r['class_ids'], r['scores']\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        class_id = class_ids[i]\n",
        "        class_name = KNOWN_CLASSES[class_id - 1]  # Adjust for background class\n",
        "        score = scores[i]\n",
        "\n",
        "        # Filter by confidence score and known classes\n",
        "        if class_name in KNOWN_CLASSES and score > CONFIDENCE_THRESHOLDS[class_name]:\n",
        "            box = boxes[i]\n",
        "            tracks[class_name].append(box)  # Save for tracking\n",
        "\n",
        "            # Draw the tracked boxes on the image\n",
        "            color = mrcnn.visualize.random_colors(1)[0]\n",
        "            y1, x1, y2, x2 = box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(image, f'{class_name} {score:.2f}', (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "            # Apply object tracking logic (e.g., IoU)\n",
        "            if len(tracks[class_name]) > 1:\n",
        "                prev_box = tracks[class_name][-2]\n",
        "                iou = compute_iou(prev_box, box)\n",
        "                if iou > 0.3:  # IoU threshold for tracking\n",
        "                    # Continue tracking\n",
        "                    cv2.putText(image, f'Tracked {class_name}', (x1, y2 + 20),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame from BGR to RGB for Mask R-CNN model\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model.detect([rgb_frame], verbose=0)\n",
        "    r = results[0]\n",
        "\n",
        "    # Process detections (filter + tracking)\n",
        "    output_frame = process_detections(rgb_frame, r)\n",
        "\n",
        "    # Convert back to BGR for OpenCV output\n",
        "    output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Write output frame to video file\n",
        "    out.write(output_frame)\n",
        "\n",
        "    # Display the frame with detections and tracking\n",
        "    cv2.imshow(\"Frame\", output_frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and output video\n",
        "video_capture.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "d6Owmio7O-0c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}